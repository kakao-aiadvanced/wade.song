{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-30T06:52:29.910406Z",
     "start_time": "2024-07-30T06:52:29.019436Z"
    }
   },
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kakao/PycharmProjects/wade.song/.venv/lib/python3.8/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T06:53:58.582834Z",
     "start_time": "2024-07-30T06:53:58.252149Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Load, chunk and index the contents of the blog.\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "               \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "               \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "for doc in docs:\n",
    "    print(doc.page_content[:100])  # 각 문서의 첫 100자를 출력"
   ],
   "id": "2daacd506728b712",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |\n",
      "\n",
      "\n",
      "      Prompt Engineering\n",
      "    \n",
      "Date: March 15, 2023  |  Estimated Reading Time: 21 min  |  Author: \n",
      "\n",
      "\n",
      "      Adversarial Attacks on LLMs\n",
      "    \n",
      "Date: October 25, 2023  |  Estimated Reading Time: 33 min  \n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T06:54:58.997260Z",
     "start_time": "2024-07-30T06:54:58.991250Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "splits[-10:]"
   ],
   "id": "fa107bdcfdb3c5f2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/'}, page_content='Inner maximization: find the most effective adversarial data point, $\\\\mathbf{x} + \\\\boldsymbol{\\\\delta}$, that leads to high loss. All the adversarial attack methods eventually come down to ways to maximize the loss in the inner loop.\\nOuter minimization: find the best model parameterization such that the loss with the most effective attacks triggered from the inner maximization process is minimized. Naive way to train a robust model is to replace each data point with their perturbed versions, which can be multiple adversarial variants of one data point.\\n\\n\\nFig. 17. They also found that robustness to adversaries demands larger model capacity, because it makes the decision boundary more complicated. Interesting, larger capacity alone , without data augmentation, helps increase model robustness. (Image source: Madry et al. 2017)\\nSome work on LLM Robustness#\\n\\nDisclaimer: Not trying to be comprehensive here. Need a separate blog post to go deeper.)'),\n",
       " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/'}, page_content='One simple and intuitive way to defend the model against adversarial attacks is to explicitly instruct model to be responsible, not generating harmful content (Xie et al. 2023). It can largely reduce the success rate of jailbreak attacks, but has side effects for general model quality due to the model acting more conservatively (e.g. for creative writing) or incorrectly interpreting the instruction under some scenarios (e.g. safe-unsafe classification).'),\n",
       " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/'}, page_content='The most common way to mitigate risks of adversarial attacks is to train the model on those attack samples, known as adversarial training. It is considered as the strongest defense but leading to tradeoff between robustness and model performance. In an experiment by Jain et al. 2023, they tested two adversarial training setups: (1) run gradient descent on harmful prompts paired with \"I\\'m sorry. As a ...\" response; (2) run one descent step on a refusal response and an ascend step on a red-team bad response per training step. The method (2) ends up being quite useless because the model generation quality degrades a lot, while the drop in attack success rate is tiny.'),\n",
       " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/'}, page_content='White-box attacks often lead to nonsensical adversarial prompts and thus they can be detected by examining perplexity. Of course, a white-box attack can directly bypass this by explicitly optimizing for lower perplexity, such as UAT-LM, a variation of UAT. However, there is a tradeoff and it can lead to lower attack success rate.'),\n",
       " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/'}, page_content='Fig. 18. Perplexity filter can block attacks by [Zou et al. (2023)](https://arxiv.org/abs/2307.15043). \"PPL Passed\" and \"PPL Window Passed\" are the rates at which harmful prompts with an adversarial suffix bypass the filter without detection. The lower the pass rate the better the filter is. (Image source: Jain et al. 2023)\\nJain et al. 2023 also tested methods of preprocessing text inputs to remove adversarial modifications while semantic meaning remains.\\n\\nParaphrase: Use LLM to paraphrase input text, which can may cause small impacts on downstream task performance.\\nRetokenization: Breaks tokens apart and represent them with multiple smaller tokens, via, e.g. BPE-dropout (drop random p% tokens). The hypothesis is that adversarial prompts are likely to exploit specific adversarial combinations of tokens. This does help degrade the attack success rate but is limited, e.g. 90+% down to 40%.\\n\\nCitation#\\nCited as:'),\n",
       " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/'}, page_content='Citation#\\nCited as:\\n\\nWeng, Lilian. (Oct 2023). “Adversarial Attacks on LLMs”. Lil’Log. https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/.'),\n",
       " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/'}, page_content='Or\\n@article{weng2023attack,\\n  title   = \"Adversarial Attacks on LLMs\",\\n  author  = \"Weng, Lilian\",\\n  journal = \"lilianweng.github.io\",\\n  year    = \"2023\",\\n  month   = \"Oct\",\\n  url     = \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\"\\n}\\nReferences#\\n[1] Madry et al. “Towards Deep Learning Models Resistant to Adversarial Attacks”. ICLR 2018.\\n[2] Ribeiro et al. “Semantically equivalent adversarial rules for debugging NLP models”. ACL 2018.\\n[3] Guo et al. “Gradient-based adversarial attacks against text transformers”. arXiv preprint arXiv:2104.13733 (2021).\\n[4] Ebrahimi et al. “HotFlip: White-Box Adversarial Examples for Text Classification”. ACL 2018.\\n[5] Wallace et al. “Universal Adversarial Triggers for Attacking and Analyzing NLP.” EMNLP-IJCNLP 2019. | code\\n[6] Mehrabi et al. “Robust Conversational Agents against Imperceptible Toxicity Triggers.” NAACL 2022.'),\n",
       " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/'}, page_content='[6] Mehrabi et al. “Robust Conversational Agents against Imperceptible Toxicity Triggers.” NAACL 2022.\\n[7] Zou et al. “Universal and Transferable Adversarial Attacks on Aligned Language Models.” arXiv preprint arXiv:2307.15043 (2023)\\n[8] Deng et al. “RLPrompt: Optimizing Discrete Text Prompts with Reinforcement Learning.” EMNLP 2022.\\n[9] Jin et al. “Is BERT Really Robust? A Strong Baseline for Natural Language Attack on Text Classification and Entailment.” AAAI 2020.\\n[10] Li et al. “BERT-Attack: Adversarial Attack Against BERT Using BERT.” EMNLP 2020.\\n[11] Morris et al. \"TextAttack: A Framework for Adversarial Attacks, Data Augmentation, and Adversarial Training in NLP.\" EMNLP 2020.\\n[12] Xu et al. “Bot-Adversarial Dialogue for Safe Conversational Agents.” NAACL 2021.\\n[13] Ziegler et al. “Adversarial training for high-stakes reliability.” NeurIPS 2022.'),\n",
       " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/'}, page_content='[12] Xu et al. “Bot-Adversarial Dialogue for Safe Conversational Agents.” NAACL 2021.\\n[13] Ziegler et al. “Adversarial training for high-stakes reliability.” NeurIPS 2022.\\n[14] Anthropic, “Red Teaming Language Models to Reduce Harms: Methods, Scaling Behaviors, and Lessons Learned.” arXiv preprint arXiv:2202.03286 (2022)\\n[15] Perez et al. “Red Teaming Language Models with Language Models.” arXiv preprint arXiv:2202.03286 (2022)\\n[16] Ganguli et al. “Red Teaming Language Models to Reduce Harms: Methods, Scaling Behaviors, and Lessons Learned.” arXiv preprint arXiv:2209.07858 (2022)\\n[17] Mehrabi et al. “FLIRT: Feedback Loop In-context Red Teaming.” arXiv preprint arXiv:2308.04265 (2023)\\n[18] Casper et al. “Explore, Establish, Exploit: Red Teaming Language Models from Scratch.” arXiv preprint arXiv:2306.09442 (2023)\\n[19] Xie et al. “Defending ChatGPT against Jailbreak Attack via Self-Reminder.” Research Square (2023)'),\n",
       " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/'}, page_content='[19] Xie et al. “Defending ChatGPT against Jailbreak Attack via Self-Reminder.” Research Square (2023)\\n[20] Jones et al. “Automatically Auditing Large Language Models via Discrete Optimization.” arXiv preprint arXiv:2303.04381 (2023)\\n[21] Greshake et al. “Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection.” arXiv preprint arXiv:2302.12173(2023)\\n[22] Jain et al. “Baseline Defenses for Adversarial Attacks Against Aligned Language Models.” arXiv preprint arXiv:2309.00614 (2023)\\n[23] Wei et al. “Jailbroken: How Does LLM Safety Training Fail?” arXiv preprint arXiv:2307.02483 (2023)\\n[24] Wei & Zou. “EDA: Easy data augmentation techniques for boosting performance on text classification tasks.”  EMNLP-IJCNLP 2019.\\n[25] www.jailbreakchat.com\\n[26] WitchBOT. “You can use GPT-4 to create prompt injections against GPT-4” Apr 2023.')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T06:57:27.239015Z",
     "start_time": "2024-07-30T06:57:20.307445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
   ],
   "id": "17f06056522e7715",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T06:57:32.597764Z",
     "start_time": "2024-07-30T06:57:29.856259Z"
    }
   },
   "cell_type": "code",
   "source": "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"))",
   "id": "5c8ef05ebace2071",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T07:11:17.933349Z",
     "start_time": "2024-07-30T07:11:17.466389Z"
    }
   },
   "cell_type": "code",
   "source": [
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={'k': 6, 'lambda_mult': 0.25}\n",
    ")\n",
    "retrieved_docs = retriever.invoke(\"agent memory\")"
   ],
   "id": "d0f3768994e54d3e",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T07:22:15.019448Z",
     "start_time": "2024-07-30T07:22:15.017402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def format_docs(docs):\n",
    "    formated = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "    return formated"
   ],
   "id": "d27d9b19539efb42",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T07:11:23.441372Z",
     "start_time": "2024-07-30T07:11:23.423530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ],
   "id": "235720e0ecbcb6c",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T08:10:04.560853Z",
     "start_time": "2024-07-30T08:10:04.554597Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "#User query와 retrieved chunk 에 대해 relevance 가 있는지를 평가하는 시스템 프롬프트 작성\n",
    "def prompt_relevance():\n",
    "    res = '''\n",
    "**System Prompt:**\n",
    "\n",
    "You are provided with a User query and a retrieved chunk of text. Your task is to evaluate whether the retrieved chunk is relevant to the User query. \n",
    "\n",
    "1. **User Query:** \n",
    "```\n",
    "{question}\n",
    "```\n",
    "\n",
    "2. **Retrieved Chunk:** \n",
    "```\n",
    "{context}\n",
    "```\n",
    "\n",
    "\n",
    "Please analyze the retrieved chunk and determine if it is relevant to the User query. \n",
    "\n",
    "If the chunk is relevant to the query, output: \n",
    "{{\"relevance\": \"yes\"}}\n",
    "\n",
    "If the chunk is not relevant to the query, output: \n",
    "{{\"relevance\": \"no\"}}\n",
    "\n",
    "Please ensure your evaluation is based on the relevance of the content of the retrieved chunk in relation to the User query.\n",
    "    '''\n",
    "    return res\n",
    "\n",
    "\n"
   ],
   "id": "7a3627c2aa1335ce",
   "outputs": [],
   "execution_count": 99
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T08:13:01.507900Z",
     "start_time": "2024-07-30T08:12:57.504221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "retriever = vectorstore.as_retriever()\n",
    "retrieved_docs2 = retriever.invoke(\"What is decomposition?\")\n",
    "for retrieved_doc in retrieved_docs2:\n",
    "    prompt_relevance_res = prompt_relevance()\n",
    "    prompt = PromptTemplate(\n",
    "        template=prompt_relevance(),\n",
    "        input_variables=[\"question\", \"context\"]\n",
    "    )\n",
    "    \n",
    "\n",
    "    chain = RunnablePassthrough() | prompt | llm | JsonOutputParser()\n",
    "    result = chain.invoke({\"question\": \"What is decomposition?\", \"context\": retrieved_doc.page_content})\n",
    "    "
   ],
   "id": "5ed000909bb7b67",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "{'relevance': 'no'}\n",
      "Fig. 1. Overview of a LLM-powered autonomous agent system.\n",
      "Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "{'relevance': 'yes'}\n",
      "Zero-shot CoT. Use natural language statement like Let's think step by step to explicitly encourage the model to first generate reasoning chains and then to prompt with Therefore, the answer is to produce answers (Kojima et al. 2022 ). Or a similar statement Let's work this out it a step by step to be sure we have the right answer (Zhou et al. 2022).\n",
      "\n",
      "Question: Marty has 100 centimeters of ribbon that he must cut into 4 equal parts. Each of the cut parts must be divided into 5 equal parts. How long will each final cut be?\n",
      "Answer: Let's think step by step.\n",
      "Tips and Extensions#\n",
      "\n",
      "\n",
      "Self-consistency sampling can improve reasoning accuracy by sampling a number of diverse answers and then taking the majority vote. (Wang et al. 2022a)\n",
      "{'relevance': 'no'}\n",
      "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\n",
      "Self-Reflection#\n",
      "Self-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\n",
      "{'relevance': 'no'}\n"
     ]
    }
   ],
   "execution_count": 105
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T08:18:27.805483Z",
     "start_time": "2024-07-30T08:18:27.797408Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def check_relevance(question, retrieved_chunk):\n",
    "    prompt = PromptTemplate(\n",
    "        template=prompt_relevance(),\n",
    "        input_variables=[\"question\", \"context\"]\n",
    "    )\n",
    "\n",
    "\n",
    "    chain = RunnablePassthrough() | prompt | llm | JsonOutputParser()\n",
    "    result = chain.invoke({\"question\": question, \"context\": retrieved_chunk})\n",
    "    return result.get(\"relevance\") == \"yes\"\n",
    "\n",
    "def invoke_and_filter_related_docs(question):\n",
    "    retrieved_docs2 = retriever.invoke(question)\n",
    "    res = []\n",
    "    for retrieved_doc in retrieved_docs2:\n",
    "        if check_relevance(question, retrieved_doc.page_content):\n",
    "            res.append(retrieved_doc.page_content)\n",
    "    return res"
   ],
   "id": "74adeba10e90f88a",
   "outputs": [],
   "execution_count": 117
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T08:18:31.532741Z",
     "start_time": "2024-07-30T08:18:28.630535Z"
    }
   },
   "cell_type": "code",
   "source": "print(invoke_and_filter_related_docs(\"What is decomposition?\"))",
   "id": "2e607800ad5bd33a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.']\n"
     ]
    }
   ],
   "execution_count": 118
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T08:29:08.606670Z",
     "start_time": "2024-07-30T08:29:07.607184Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc for doc in docs)\n",
    "\n",
    "\n",
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "question = \"What is Task Decomposition?\"\n",
    "rag_chain = (\n",
    "        {\"context\": lambda: format_docs(invoke_and_filter_related_docs(question)), \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain.invoke(question)"
   ],
   "id": "96c5deed22492d2d",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "<lambda>() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[130], line 21\u001B[0m\n\u001B[1;32m     13\u001B[0m question \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWhat is Task Decomposition?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     14\u001B[0m rag_chain \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m     15\u001B[0m         {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontext\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;01mlambda\u001B[39;00m: format_docs(invoke_and_filter_related_docs(question)), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mquestion\u001B[39m\u001B[38;5;124m\"\u001B[39m: RunnablePassthrough()}\n\u001B[1;32m     16\u001B[0m         \u001B[38;5;241m|\u001B[39m prompt\n\u001B[1;32m     17\u001B[0m         \u001B[38;5;241m|\u001B[39m llm\n\u001B[1;32m     18\u001B[0m         \u001B[38;5;241m|\u001B[39m StrOutputParser()\n\u001B[1;32m     19\u001B[0m )\n\u001B[0;32m---> 21\u001B[0m \u001B[43mrag_chain\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquestion\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/wade.song/.venv/lib/python3.8/site-packages/langchain_core/runnables/base.py:2873\u001B[0m, in \u001B[0;36mRunnableSequence.invoke\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m   2869\u001B[0m config \u001B[38;5;241m=\u001B[39m patch_config(\n\u001B[1;32m   2870\u001B[0m     config, callbacks\u001B[38;5;241m=\u001B[39mrun_manager\u001B[38;5;241m.\u001B[39mget_child(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mseq:step:\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   2871\u001B[0m )\n\u001B[1;32m   2872\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m-> 2873\u001B[0m     \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mstep\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2874\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   2875\u001B[0m     \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m step\u001B[38;5;241m.\u001B[39minvoke(\u001B[38;5;28minput\u001B[39m, config)\n",
      "File \u001B[0;32m~/PycharmProjects/wade.song/.venv/lib/python3.8/site-packages/langchain_core/runnables/base.py:3562\u001B[0m, in \u001B[0;36mRunnableParallel.invoke\u001B[0;34m(self, input, config)\u001B[0m\n\u001B[1;32m   3549\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m get_executor_for_config(config) \u001B[38;5;28;01mas\u001B[39;00m executor:\n\u001B[1;32m   3550\u001B[0m         futures \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m   3551\u001B[0m             executor\u001B[38;5;241m.\u001B[39msubmit(\n\u001B[1;32m   3552\u001B[0m                 step\u001B[38;5;241m.\u001B[39minvoke,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   3560\u001B[0m             \u001B[38;5;28;01mfor\u001B[39;00m key, step \u001B[38;5;129;01min\u001B[39;00m steps\u001B[38;5;241m.\u001B[39mitems()\n\u001B[1;32m   3561\u001B[0m         ]\n\u001B[0;32m-> 3562\u001B[0m         output \u001B[38;5;241m=\u001B[39m {key: future\u001B[38;5;241m.\u001B[39mresult() \u001B[38;5;28;01mfor\u001B[39;00m key, future \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(steps, futures)}\n\u001B[1;32m   3563\u001B[0m \u001B[38;5;66;03m# finish the root run\u001B[39;00m\n\u001B[1;32m   3564\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/PycharmProjects/wade.song/.venv/lib/python3.8/site-packages/langchain_core/runnables/base.py:3562\u001B[0m, in \u001B[0;36m<dictcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m   3549\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m get_executor_for_config(config) \u001B[38;5;28;01mas\u001B[39;00m executor:\n\u001B[1;32m   3550\u001B[0m         futures \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m   3551\u001B[0m             executor\u001B[38;5;241m.\u001B[39msubmit(\n\u001B[1;32m   3552\u001B[0m                 step\u001B[38;5;241m.\u001B[39minvoke,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   3560\u001B[0m             \u001B[38;5;28;01mfor\u001B[39;00m key, step \u001B[38;5;129;01min\u001B[39;00m steps\u001B[38;5;241m.\u001B[39mitems()\n\u001B[1;32m   3561\u001B[0m         ]\n\u001B[0;32m-> 3562\u001B[0m         output \u001B[38;5;241m=\u001B[39m {key: \u001B[43mfuture\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m key, future \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(steps, futures)}\n\u001B[1;32m   3563\u001B[0m \u001B[38;5;66;03m# finish the root run\u001B[39;00m\n\u001B[1;32m   3564\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/concurrent/futures/_base.py:444\u001B[0m, in \u001B[0;36mFuture.result\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    442\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n\u001B[1;32m    443\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;241m==\u001B[39m FINISHED:\n\u001B[0;32m--> 444\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__get_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    445\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    446\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTimeoutError\u001B[39;00m()\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/concurrent/futures/_base.py:389\u001B[0m, in \u001B[0;36mFuture.__get_result\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    387\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception:\n\u001B[1;32m    388\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 389\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception\n\u001B[1;32m    390\u001B[0m     \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    391\u001B[0m         \u001B[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001B[39;00m\n\u001B[1;32m    392\u001B[0m         \u001B[38;5;28mself\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/concurrent/futures/thread.py:57\u001B[0m, in \u001B[0;36m_WorkItem.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     54\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 57\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m     59\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfuture\u001B[38;5;241m.\u001B[39mset_exception(exc)\n",
      "File \u001B[0;32m~/PycharmProjects/wade.song/.venv/lib/python3.8/site-packages/langchain_core/runnables/base.py:4441\u001B[0m, in \u001B[0;36mRunnableLambda.invoke\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m   4427\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Invoke this Runnable synchronously.\u001B[39;00m\n\u001B[1;32m   4428\u001B[0m \n\u001B[1;32m   4429\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4438\u001B[0m \u001B[38;5;124;03m    TypeError: If the Runnable is a coroutine function.\u001B[39;00m\n\u001B[1;32m   4439\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   4440\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfunc\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m-> 4441\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_with_config\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   4442\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_invoke\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4443\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4444\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_config\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4445\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4446\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4447\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   4448\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[1;32m   4449\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot invoke a coroutine function synchronously.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   4450\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUse `ainvoke` instead.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   4451\u001B[0m     )\n",
      "File \u001B[0;32m~/PycharmProjects/wade.song/.venv/lib/python3.8/site-packages/langchain_core/runnables/base.py:1784\u001B[0m, in \u001B[0;36mRunnable._call_with_config\u001B[0;34m(self, func, input, config, run_type, **kwargs)\u001B[0m\n\u001B[1;32m   1780\u001B[0m     context \u001B[38;5;241m=\u001B[39m copy_context()\n\u001B[1;32m   1781\u001B[0m     context\u001B[38;5;241m.\u001B[39mrun(_set_config_context, child_config)\n\u001B[1;32m   1782\u001B[0m     output \u001B[38;5;241m=\u001B[39m cast(\n\u001B[1;32m   1783\u001B[0m         Output,\n\u001B[0;32m-> 1784\u001B[0m         \u001B[43mcontext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1785\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcall_func_with_variable_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[1;32m   1786\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[1;32m   1787\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[1;32m   1788\u001B[0m \u001B[43m            \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1789\u001B[0m \u001B[43m            \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1790\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1791\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m   1792\u001B[0m     )\n\u001B[1;32m   1793\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m   1794\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_chain_error(e)\n",
      "File \u001B[0;32m~/PycharmProjects/wade.song/.venv/lib/python3.8/site-packages/langchain_core/runnables/config.py:404\u001B[0m, in \u001B[0;36mcall_func_with_variable_args\u001B[0;34m(func, input, config, run_manager, **kwargs)\u001B[0m\n\u001B[1;32m    402\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m run_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m accepts_run_manager(func):\n\u001B[1;32m    403\u001B[0m     kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_manager\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m run_manager\n\u001B[0;32m--> 404\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/wade.song/.venv/lib/python3.8/site-packages/langchain_core/runnables/base.py:4297\u001B[0m, in \u001B[0;36mRunnableLambda._invoke\u001B[0;34m(self, input, run_manager, config, **kwargs)\u001B[0m\n\u001B[1;32m   4295\u001B[0m                 output \u001B[38;5;241m=\u001B[39m chunk\n\u001B[1;32m   4296\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 4297\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mcall_func_with_variable_args\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   4298\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m   4299\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4300\u001B[0m \u001B[38;5;66;03m# If the output is a Runnable, invoke it\u001B[39;00m\n\u001B[1;32m   4301\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(output, Runnable):\n",
      "File \u001B[0;32m~/PycharmProjects/wade.song/.venv/lib/python3.8/site-packages/langchain_core/runnables/config.py:404\u001B[0m, in \u001B[0;36mcall_func_with_variable_args\u001B[0;34m(func, input, config, run_manager, **kwargs)\u001B[0m\n\u001B[1;32m    402\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m run_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m accepts_run_manager(func):\n\u001B[1;32m    403\u001B[0m     kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_manager\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m run_manager\n\u001B[0;32m--> 404\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mTypeError\u001B[0m: <lambda>() takes 0 positional arguments but 1 was given"
     ]
    }
   ],
   "execution_count": 130
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "def check_hall()",
   "id": "76d38db281ee97d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
